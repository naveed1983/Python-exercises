{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Expectation Maximization and Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning contents:\n",
    "\n",
    "1. Mixture of Gaussians: Expectation-Maximization\n",
    "    - Display results\n",
    "    - Nearest Centroid-based classification\n",
    "2. Principal Component Analysis\n",
    "    - Generate data\n",
    "    - Apply PCA\n",
    "    - Display projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from sklearn import datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "import seaborn as sns; sns.set(); sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use `iris` dataset from `sklearn` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_x = np.array(iris.data[:, :2])  # we only take the first two features.\n",
    "iris_t = np.array(iris.target)\n",
    "\n",
    "def plot_iris(legend=True, classes=iris_t, target=plt):\n",
    "    scatter = target.scatter(iris_x[:, 0], iris_x[:, 1], c=classes, alpha=0.7, cmap='rainbow', edgecolor='none')\n",
    "    if legend:\n",
    "        legend = target.legend(*scatter.legend_elements(), loc=\"upper left\", title=\"Classes\")\n",
    "        return (scatter, legend)\n",
    "    return (scatter, )\n",
    "\n",
    "plot_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Mixture of Gaussians: Expectation-Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write a function `gaussian_mixture` that takes data point `x` (say, a vector in D-dimensional space), set of multivariate `means` and respective `covariances`, and `pis` (mixing coefficients as defined in a Gaussian mixture model) and should return PDF value of mixture model at the point x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture(x, means, covariances, pis):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write a function `expectation_maximization_gaussian` that takes initial mean vectors `mus_0`, initial covariance matrices `covariances_0`, initial mixing coefficient values `pis_0`, input data set `data_x` and a callback `on_step`."
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `on_step` is a function that takes current set of `mus`, corresponding `covariances` and `pis`, value of `log_likelihood` and list of class `predictions` for each point and should be called each iteration step. Remember that you do not need to define this function as it has already been defined in the later part of the code, you just need to call it after updating parameters in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization_gaussian(mus_0, covariances_0, pis_0, data_x, on_step):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_mixtures(mus, covariances, pis, data, classes, cmap='rainbow', target=plt):\n",
    "    \n",
    "    lx = min(data[:, 0])\n",
    "    rx = max(data[:, 0])\n",
    "    by = min(data[:, 1])\n",
    "    uy = max(data[:, 1])\n",
    "\n",
    "    x, y = np.mgrid[lx:rx:.01, by:uy:.01]\n",
    "    pos = np.dstack((x, y))\n",
    "    \n",
    "    probabilities = list(map(\n",
    "        lambda x: gaussian_mixture(x, mus, covariances, pis),\n",
    "        pos\n",
    "    ))\n",
    "    \n",
    "    target.contour(x, y, probabilities, cmap=cmap)\n",
    "    \n",
    "    plot = plot_iris(classes=classes, target=target)\n",
    "    # scatter = target.scatter(mus[:, 0], mus[:, 1], c=[0, 1, 2], cmap='rainbow', marker='data', s=300, edgecolors='black')\n",
    "    return (*plot, )\n",
    "\n",
    "\n",
    "def plot_mesh(pred_fn, n_class=3, x_min=4, x_max=8, y_min=2, y_max=4.5, target=plt):\n",
    "    h = 0.1  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = np.array(list(map(lambda x: pred_fn(np.array(x)), np.c_[xx.ravel(), yy.ravel()])))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = target.contourf(xx, yy, Z, alpha = 0.1, cmap=plt.cm.get_cmap('rainbow', n_class))\n",
    "    target.axis('tight')\n",
    "    if hasattr(target, 'xlim'):\n",
    "        target.xlim(x_min, x_max)\n",
    "        target.ylim(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "classes = 3\n",
    "\n",
    "all_steps_em = []\n",
    "\n",
    "mus_0 = iris_x[:classes]\n",
    "covariances_0 = np.array([np.cov(iris_x.T)] * classes)\n",
    "pis_0 = np.array([1/classes] * classes)\n",
    "\n",
    "expectation_maximization_gaussian(\n",
    "    mus_0, covariances_0, pis_0, iris_x,\n",
    "    lambda mus, covs, pis, log_likelihood, predictions: all_steps_em.append((mus, covs, pis, log_likelihood, predictions))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(all_steps_em, data_x):\n",
    "    \n",
    "    fig, (ax, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    \n",
    "    log_likelihoods = list(map(lambda x: x[3], all_steps_em))\n",
    "    \n",
    "    def animate(i):\n",
    "        ax.cla()\n",
    "        ax2.cla()\n",
    "        \n",
    "        predictions = all_steps_em[i][4]\n",
    "        \n",
    "        plot1 = plot_gaussian_mixtures(all_steps_em[i][0], all_steps_em[i][1], all_steps_em[i][2], iris_x, predictions, target=ax)\n",
    "                \n",
    "        ax2.plot(list(range(i)), log_likelihoods[:i], '-o')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Log Likelihood')\n",
    "        return plot1\n",
    "    \n",
    "    anim = FuncAnimation(\n",
    "        fig, animate,\n",
    "        frames=len(all_steps_em), interval=500, blit=True\n",
    "    )\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "create_animation(all_steps_em, iris_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Nearest Centroid-based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nearest_centroid_based_class` takes data point `x`, set of means `mus` and `covariances` and returns class of this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_centroid_based_class(x, mus, covariances):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(all_steps_em, data_x):\n",
    "    \n",
    "    fig, (ax, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    \n",
    "    log_likelihoods = list(map(lambda x: x[3], all_steps_em))\n",
    "    \n",
    "    def animate(i):\n",
    "        ax.cla()\n",
    "        ax2.cla()\n",
    "        \n",
    "        predictions = all_steps_em[i][4]\n",
    "        \n",
    "        plot1 = plot_gaussian_mixtures(all_steps_em[i][0], all_steps_em[i][1], all_steps_em[i][2], iris_x, predictions, target=ax)\n",
    "        \n",
    "        plot_mesh(\n",
    "            lambda x: nearest_centroid_based_class(x, all_steps_em[i][0], all_steps_em[i][1]),\n",
    "            n_class=len(all_steps_em[i][0]), target=ax\n",
    "        )\n",
    "        \n",
    "        ax2.plot(list(range(i)), log_likelihoods[:i], '-o')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Log Likelihood')\n",
    "        return plot1\n",
    "    \n",
    "    anim = FuncAnimation(\n",
    "        fig, animate,\n",
    "        frames=len(all_steps_em), interval=500, blit=True\n",
    "    )\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "create_animation(all_steps_em, iris_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris4_x = np.array(iris.data[:, :4])\n",
    "\n",
    "def plot_classes_3d(data, classes):\n",
    "\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8, 6))\n",
    "    ax = Axes3D(fig, elev=-150, azim=110)\n",
    "    ax.scatter(data[:, 0], data[:, 1], data[:, 2], c=classes,\n",
    "               cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "    plt.show()\n",
    "plot_classes_3d(iris4_x[:, :3], iris_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pca_projection` takes data points `data`, number of `components` as arguments and returns PCA projection of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_projection(data, components):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Display projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(data, classes, legend=True, target=plt):\n",
    "    scatter = target.scatter(data[:, 0], data[:, 1], c=classes, alpha=0.7, cmap='rainbow', edgecolor='none')\n",
    "    if legend:\n",
    "        legend = target.legend(*scatter.legend_elements(), loc=\"upper left\", title=\"Classes\")\n",
    "        return (scatter, legend)\n",
    "    return (scatter, )\n",
    "\n",
    "projected_data = pca_projection(iris4_x, 2)\n",
    "plot_classes(projected_data, iris_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_data = pca_projection(iris4_x, 3)\n",
    "plot_classes_3d(projected_data, iris_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
