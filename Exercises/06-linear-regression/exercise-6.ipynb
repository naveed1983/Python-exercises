{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning contents:\n",
    "\n",
    "1. Linear models\n",
    "    - Polynomial function\n",
    "    - Radial basis function\n",
    "    - Sigmoidal basis function\n",
    "    - Optimization of Error function\n",
    "    - Test models\n",
    "2. Bayesian Linear Regression \n",
    "    - Generate data\n",
    "    - Fit the data\n",
    "    - Predictive distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import seaborn as sns; sns.set(); sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(x): return np.sin(2*np.pi*x)\n",
    "\n",
    "def generate_data(size):\n",
    "    rng = np.random.RandomState(26052605)\n",
    "    x_train = rng.uniform(0., 1., size)\n",
    "    y_train = target_func(x_train) + rng.normal(scale=0.1, size=size)\n",
    "    x_test = np.linspace(0., 1., 100)\n",
    "    y_test = target_func(x_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = generate_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, y_test, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the function named linear that takes data point x (scalar), a basis function, and weights (list|ndarray (Mx1) and returns the output of linear basis function model (2nd equation in slide 5 of lecture 11, eq (3.3) in text book). The basis function (Phi(x)) that goes as input to linear will be defined later but it takes x (scalar) and i (index) and returns Phi_i(x) (which is a scalar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, basis, weights):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Polynomial basis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `create_polynomial` below, write the code of `polynomial` function that takes data point `x` (scalar) and `i` (index) and returns the i-th value (scalar) of a polynomial basis function Phi_i(x) (see equation in slide 7 of lecture 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polynomial():\n",
    "    def polynomial(x, i):\n",
    "        pass\n",
    "    \n",
    "    return polynomial"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the different polynomial basis functions for input x ranging from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "n = 11\n",
    "\n",
    "polynomial = create_polynomial()\n",
    "\n",
    "for i in range(n):\n",
    "    y = list(map(lambda x: polynomial(x, i), x))\n",
    "    plt.plot(x, y, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Radial basis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In create_radial function below, write the code of radial function that takes data point x (scalar) and i (index) and returns the i-th value (scalar) of a radial basis function Phi_i(x) (see equation in slide 8 of lecture 11). The outer create_radial function takes mean and variance as input which are used by the radial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radial(means, variance):\n",
    "    def radial(x, i):\n",
    "        pass\n",
    "    \n",
    "    return radial"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the different radial basis functions for input x ranging from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "n = 11\n",
    "\n",
    "radial = create_radial(np.linspace(-1, 1, 11), 0.1)\n",
    "\n",
    "for i in range(n):\n",
    "    y = list(map(lambda x: radial(x, i), x))\n",
    "    plt.plot(x, y, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Sigmoidal basis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In create_sigmoidal function below, write the code of sigmoidal function that takes data point x (scalar) and i (index) and returns the i-th value (scalar) of a radial basis function Phi_i(x) (see equation in slide 9 of lecture 11). The outer create_sigmoidal function takes mean and s as input which are used by the sigmoidal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sigmoidal(means, s):\n",
    "    def sigmoidal(x, i):\n",
    "        pass\n",
    "    \n",
    "    return sigmoidal"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the different sigmoidal basis functions for input x ranging from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "n = 11\n",
    "\n",
    "sigmoidal = create_sigmoidal(np.linspace(-1, 1, 11), 0.1)\n",
    "\n",
    "for i in range(n):\n",
    "    y = list(map(lambda x: sigmoidal(x, i), x))\n",
    "    plt.plot(x, y, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Optimization of Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the `optimial_weights` function that takes `basis` function (linear function that takes `x` (scalar) and `i` (index)), `inputs` (list Nx1), `targets` (list Nx1), and `M` (scalar number of weights) as parameters and returns optimal weights (list|ndarray (Mx1)) for this data and basis function. The output weights from this function should correspond to the output of the last equation given in slide 11 of lecture 11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimial_weights(basis, inputs, targets, M):\n",
    "     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(basis, M, label=''):\n",
    "    plt.plot(x_test, list(map(lambda x: linear(x, basis, optimial_weights(basis, x_train, y_train, M)), x_test)), '-', label=label)\n",
    "    plt.plot(x_train, y_train, 'og')\n",
    "    plt.legend()"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will test the performance of the optimal model using different basis function on input data generated at the start of the notebook. Which model you believe performs the best on this data? Does the model size affect the model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(create_radial(np.linspace(-1, 1, 10), 0.1), 7, 'radial, M=7')\n",
    "test(create_radial(np.linspace(-1, 1, 10), 0.1), 4, 'radial, M=4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(create_polynomial(), 7, 'polynomial, M=7')\n",
    "test(create_polynomial(), 4, 'polynomial, M=4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(create_sigmoidal(np.linspace(0, 1, 8), 1), 7, 'sigmoidal, M=7')\n",
    "test(create_sigmoidal(np.linspace(0, 1, 8), 1), 4, 'sigmoidal, M=4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bayesian Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Generate data"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions generate training and test data corresponding to a linear function. The data corresponds to a regression problem where individual input x and output y are both scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_func(x): return -0.5 + 0.3 * x\n",
    "\n",
    "def generate_line_data(size):\n",
    "    rng = np.random.RandomState(26052605)\n",
    "    x_train = rng.uniform(0., 1., size)\n",
    "    y_train = line_func(x_train) + rng.normal(scale=0.05, size=size)\n",
    "    x_test = np.linspace(0., 1., 100)\n",
    "    y_test = line_func(x_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "xl_train, yl_train, xl_test, yl_test = generate_line_data(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xl_train, yl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xl_test, yl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the bayessian_regression_fit function that takes PHI (ndarray NxM), t (ndarray Nx1 targets), alpha (scalar) and beta (scalar) as parameters and must return mean (ndarray Mx1) , and covariance (ndarray MxM) for the weight vector using a Bayesian approach (see slide 14 in lecture 12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayessian_regression_fit(PHI, t, alpha, beta):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 100\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "w0, w1 = np.meshgrid(\n",
    "    np.linspace(-1, 1, 100),\n",
    "    np.linspace(-1, 1, 100)\n",
    ")\n",
    "w = np.array([w0, w1]).transpose(1, 2, 0)\n",
    "\n",
    "basis = create_polynomial()\n",
    "\n",
    "M = 1\n",
    "\n",
    "PHI = np.array([[basis(x[q], i) for q in range(len(x))] for i in range(M + 1)]).T\n",
    "PHI_train = np.array([[basis(xl_train[q], i) for q in range(len(xl_train))] for i in range(M + 1)]).T\n",
    "\n",
    "for begin, end in [[0, 0], [0, 1], [3, 6], [4, 7], [3, 20]]:\n",
    "    \n",
    "    w_mean, w_cov = bayessian_regression_fit(PHI_train[begin:end], yl_train[begin:end], alpha, beta)\n",
    "    \n",
    "    w_sample = np.random.multivariate_normal(\n",
    "        w_mean.reshape(-1), w_cov, size=6\n",
    "    )\n",
    "    y_sample = PHI @ w_sample.T\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(-0.5, 0.3, s=200, marker=\"x\")\n",
    "    plt.contour(w0, w1, multivariate_normal.pdf(w, mean=w_mean, cov=w_cov))\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel(\"$w_0$\")\n",
    "    plt.ylabel(\"$w_1$\")\n",
    "    plt.title(\"prior/posterior\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(xl_train[:end], yl_train[:end], s=100, facecolor=\"none\", edgecolor=\"steelblue\", lw=1)\n",
    "    plt.plot(x, y_sample, c=\"orange\")\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Predictive distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the sample function which takes PHI_train (ndarray NxM), y_train (ndarray Nx1), alpha (scalar), beta (scalar), and PHI_test as parameters and returns y (ndarray N_test x 1 prediction means) and y_std (ndarray N_test x 1 prediction standard deviations). See slide 16 in lecture 12 for more details on how to implement the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(PHI_train, y_train, alpha, beta, PHI_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-3\n",
    "beta = 2\n",
    "x_train, y_train, x_test, y_test = generate_data(25)\n",
    "\n",
    "basis = create_radial(np.linspace(0, 1, 9), 0.1)\n",
    "\n",
    "M = 8\n",
    "\n",
    "PHI_train = np.array([[basis(x_train[q], i) for q in range(len(x_train))] for i in range(M + 1)]).T\n",
    "PHI_test = np.array([[basis(x_test[q], i) for q in range(len(x_test))] for i in range(M + 1)]).T\n",
    "\n",
    "for begin, end in [[0, 1], [1, 2], [2, 4], [4, 8], [8, 25]]:\n",
    "    \n",
    "    y, y_std = sample(PHI_train[begin:end], y_train[begin:end], alpha, beta, PHI_test)\n",
    "    \n",
    "    plt.scatter(x_train[:end], y_train[:end], s=100, facecolor=\"none\", edgecolor=\"steelblue\", lw=2)\n",
    "    plt.plot(x_test, y_test)\n",
    "    plt.plot(x_test, y)\n",
    "    plt.fill_between(x_test, y - y_std, y + y_std, color=\"orange\", alpha=0.5)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
