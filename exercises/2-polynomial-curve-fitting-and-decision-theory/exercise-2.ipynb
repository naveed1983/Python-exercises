{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Polynomial Curve Fitting and Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning contents:\n",
    "\n",
    "1. Linear models\n",
    "    - Linear function\n",
    "    - Error function\n",
    "    - Root meant square error\n",
    "    - Optimization of Error function\n",
    "    - Test the model\n",
    "2. Regularization\n",
    "    - Error function\n",
    "    - Optimization\n",
    "    - Test with regularization\n",
    "3. Model Selection\n",
    "    - Cross-validation\n",
    "4. Bayesian curve fitting\n",
    "    - Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will apply Linear Models for Polynomial Curve Fitting task.\n",
    "\n",
    "You have to fill empty functions (with pass in body) to match their purpose.\n",
    "\n",
    "1. You have to create a code for evaluation of a Linear Model, it's error functions and finding optimal weights with given error functions.\n",
    "2. You need to add regularization to the optimization procedure.\n",
    "3. You need to implement Cross-validation model selection technique.\n",
    "4. You need to implement Bayesian curve fitting, computing phi and S matricies at first, then using them to compute mean and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import  exp\n",
    "\n",
    "import seaborn as sns; sns.set(); sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(x): return np.sin(2*np.pi*x)\n",
    "\n",
    "def generate_data(size):\n",
    "    rng = np.random.RandomState(26052605)\n",
    "    x_train = rng.uniform(0., 1., size)\n",
    "    y_train = target_func(x_train) + rng.normal(scale=0.1, size=size)\n",
    "    x_test = np.linspace(0., 1., 100)\n",
    "    y_test = target_func(x_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = generate_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, y_test, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear` takes data point `x` and a list of `weights` as parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, weights):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`err` is a sum-of-squares error function that takes `weights`, `inputs` and `targets` as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(weights, inputs, targets):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Root meant square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erms(weights, inputs, targets):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Optimization of Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimial_weights` takes `inputs`, `targets`, and `M` (number of weights) as parameters and returns optimal weights for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimial_weights(inputs, targets, M):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(start_M, end_M, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    all_weights = []\n",
    "    \n",
    "    for M in range(start_M, end_M + 1):\n",
    "        weights = optimial_weights(x_train, y_train, M)\n",
    "        all_weights.append(weights)\n",
    "        error_train = erms(weights, x_train, y_train)\n",
    "        error_test = erms(weights, x_test, y_test)\n",
    "        results_train.append(error_train)\n",
    "        results_test.append(error_test)\n",
    "    return results_train, results_test, all_weights\n",
    "\n",
    "r_tr, r_tt, all_weights = test_all(0, 9, x_train, y_train, x_test, y_test)\n",
    "\n",
    "plt.plot(list(range(0, 10)), r_tr, '-o', label='train')\n",
    "plt.plot(list(range(0, 10)), r_tt, '-o', label='test')\n",
    "plt.xlabel('M')\n",
    "plt.ylabel('ERMS')\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights table for different `M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(all_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimated curve for `M=9` (same as the amount of data points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, list(map(lambda x: linear(x, optimial_weights(x_train, y_train, 9)), x_test)), '-')\n",
    "plt.plot(x_train, y_train, 'og')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`err_regularization` takes `weights`, `inputs`, `targets` and `l` (regularization term) and computes sum-of-squares error with weights regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_regularization(weights, inputs, targets, l):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`erms_regularization` is a regularization version of a root mean squares error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erms_regularization(weights, inputs, targets, l):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimial_weights_regularization` takes `inputs`, `targets`, `M` (number of weights) and `l` (regularization term)  as parameters and returns optimal weights (with regularization) for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimial_weights_regularization(inputs, targets, M, l):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Test with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_regularization(ls, M, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    all_weights = []\n",
    "    \n",
    "    for l in ls:\n",
    "        weights = optimial_weights_regularization(x_train, y_train, M, l)\n",
    "        all_weights.append(weights)\n",
    "        error_train = erms_regularization(weights, x_train, y_train, l)\n",
    "        error_test = erms_regularization(weights, x_test, y_test, l)\n",
    "        results_train.append(error_train)\n",
    "        results_test.append(error_test)\n",
    "    return results_train, results_test, all_weights\n",
    "\n",
    "ls = [0, exp(-18), exp(-5), exp(0)]\n",
    "\n",
    "r_tr_r, r_tt_r, all_weights_r = test_all_regularization(ls, 9, x_train, y_train, x_test, y_test)\n",
    "\n",
    "plt.plot(ls, r_tr_r, '-o', label='train')\n",
    "plt.plot(ls, r_tt_r, '-o', label='test')\n",
    "plt.xlabel('ln Lambda')\n",
    "plt.ylabel('ERMS_REGULARIZATION')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights for `M=9` with regularization terms `0`, `exp(-18)`, `exp(-5)`, `exp(0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(np.transpose(all_weights_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_lambda(l):\n",
    "    plt.plot(x_test, y_test, '-m')\n",
    "    plt.plot(x_test, list(map(lambda x: linear(x, optimial_weights_regularization(x_train, y_train, 9, l)), x_test)), '-')\n",
    "    plt.plot(x_train, y_train, 'og')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_lambda(exp(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_lambda(exp(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_lambda(exp(-18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_lambda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_cross_validation_sets` takes `S` (number of sets) and data points `x_train`, `y_train` as parameters and returns array of sets in form `[x_sub_train, y_sub_train, x_validation, y_validation]` each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_validation_sets(S, x_train, y_train):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`best_model` takes `start_M`, `end_M` (low and high limits to search for `M`), `ls` (list of regularization terms) and `sets` (cross-validation sets) and should return `(top_M, top_l, top_result_test)` with `M`, `l` and result for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(start_M, end_M, ls, sets):\n",
    "    pass\n",
    "\n",
    "\n",
    "x_cross_train, y_cross_train, _, _ = generate_data(100) \n",
    "\n",
    "M, l, r = best_model(0, 9, [0, exp(-18), exp(-5), exp(0)], create_cross_validation_sets(10, x_cross_train, y_cross_train))\n",
    "print('M =', M, 'lambda =', l, 'erms =', r)\n",
    "\n",
    "plt.plot(x_test, y_test, '-m')\n",
    "plt.plot(x_test, list(map(lambda x: linear(x, optimial_weights_regularization(x_train, y_train, M, l)), x_test)), '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Bayesian curve fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`phi` takes `x` (data point) and `M` (number of weights) as arguments and returns a vector of powers of `x` from `0` to `M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x, M):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`S` takes `alpha`, `beta`, `x` (all data points), and `M` as arguments and returns a matrix `S` that is used to compute `mean` and `variance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S(alpha, beta, x, M):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mean` takes `alpha`, `beta`, `x_star` (new point), `x` (all data points), `t` (target values), and `M` and computes mean for the Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(alpha, beta, x_star, x, t, M):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`variance` takes `alpha`, `beta`, `x_star` (new point), `x` (all data points), `t` (target values), and `M` and computes variance for the Gaussian variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(alpha, beta, x_star, x, t, M):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "beta = 1.1\n",
    "M = 9\n",
    "\n",
    "means = np.array(list(map(lambda x: mean(alpha, beta, x, x_train, y_train, M), x_test)))\n",
    "variances = np.array(list(map(lambda x: variance(alpha, beta, x, x_train, y_train, M), x_test)))\n",
    "\n",
    "plt.plot(x_train, y_train, 'og')\n",
    "plt.plot(x_test, y_test, '-m')\n",
    "plt.plot(x_test, means, '-b')\n",
    "plt.fill_between(x_test, means + variances, means - variances, color='red', alpha='0.3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
